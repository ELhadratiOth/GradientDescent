{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.set_printoptions(precision=2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| Size (sqft) | Number of Bedrooms  | Number of floors | Age of  Home | Price (1000s dollars)  |   \n",
    "| ----------------| ------------------- |----------------- |--------------|-------------- |  \n",
    "| 2104            | 5                   | 1                | 45           | 460           |  \n",
    "| 1416            | 3                   | 2                | 40           | 232           |  \n",
    "| 852             | 2                   | 1                | 35           | 178           |  \n",
    "\n",
    "\n",
    "On veut predicter les valeurs des maisons a partir de cette dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features : \n",
      " [[2104    5    1   45]\n",
      " [1416    3    2   40]\n",
      " [ 852    2    1   35]]\n",
      "House price :  [460 232 178]\n"
     ]
    }
   ],
   "source": [
    "# title Titre par d√©faut\n",
    "X_train = np.array([[2104, 5, 1, 45], [1416, 3, 2, 40], [852, 2, 1, 35]]) #Input Data\n",
    "y_train = np.array([460, 232, 178])  # reel price\n",
    "b_init = 785.1811367994083\n",
    "w_init = np.array([ 0.39133535, 18.75376741, -53.36032453, -26.42131618])\n",
    "print(\"Features : \\n\" ,  X_train)\n",
    "print(\"House price : \" , y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the model equation  : \n",
    "$$ f_{\\mathbf{w},b}(\\mathbf{x}) =  w_0x_0 + w_1x_1 +... + w_{n-1}x_{n-1} + b $$\n",
    "equivalent a :\n",
    "$$ f_{\\mathbf{w},b}(\\mathbf{x}) = \\mathbf{w} \\cdot \\mathbf{x} + b   $$ \n",
    "\n",
    "```\n",
    "where  w and b are the parameter that we need to optimise .\n",
    "( . ) c'est produit scalaire \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1270.0\n"
     ]
    }
   ],
   "source": [
    "def cal_error(X_feat, y , w, b ) :\n",
    "          # err = 0 \n",
    "          # for i in  X.shape[0] :\n",
    "          #           err += X_feat[i] * w[i]\n",
    "          # err += b \n",
    "          \n",
    "\n",
    "          err = float(np.dot(X_feat , w ) + b  - y)\n",
    "          return err # it return an array of the  error  of  each  element\n",
    "\n",
    "#test :\n",
    "\n",
    "print(cal_error(X_train[1], y_train[1] , np.array([1, 1, 1 , 2]), 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cost function :\n",
    "\n",
    "$$J(\\mathbf{w},b) = \\frac{1}{2m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)})^2 \\tag{3}$$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost function for  a random  parameters :  1.5578904428966628e-12\n"
     ]
    }
   ],
   "source": [
    "def compute_cost(X, y, w, b):\n",
    "    cost = 0.0\n",
    "\n",
    "    m = X.shape[0]  # Number of training examples\n",
    "    for i in range(m):\n",
    "\n",
    "        cost += cal_error(X[i], y[i], w, b) ** 2\n",
    "\n",
    "    cost /= (2 * m)\n",
    "    return cost\n",
    "\n",
    "print( \"The cost function for  a random  parameters : \" ,  compute_cost(X_train , y_train  ,w_init , b_init) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On doit calculer tous ces parametres et trouver les paramatres les plus optimiser\n",
    "\n",
    "$$\\begin{align*} \n",
    "& w_j = w_j -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j} \\tag{5}  \\; & \\text{for j = 0..3}\\newline\n",
    "&b\\ \\ = b -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial b} \\newline \n",
    "\\end{align*}$$\n",
    "\n",
    "\n",
    "or les derivees partielles s'ecrit sous cette forme :\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)})x_{j}^{(i)} \\tag{6}  \\\\\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial b}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)}) \\tag{7}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "compute_gradient cette fonction calculate the cost for each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(X, y, w, b):\n",
    "          m , n  = X.shape  # m nombre des rows , n nombre des features\n",
    "          grad_w = np.zeros((n,))\n",
    "          grad_b = 0.0\n",
    "          for  i in  range(m) :\n",
    "                    for j in range(n) :\n",
    "                              grad_w[j] +=   cal_error(X[i],y[i],w,b) * X[i,j]  \n",
    "                    grad_b +=  cal_error(X[i],y[i],w,b)\n",
    "                    \n",
    "          grad_w /=  m\n",
    "          grad_b /= m \n",
    "          \n",
    "          return grad_w, grad_b  \n",
    "                      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration    0: Cost 2529.4629522316304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b,w found by gradient descent: -0.00,[ 0.2   0.   -0.01 -0.07] \n",
      "prediction: 426.19 , reel value: 460\n",
      "prediction: 286.17 , reel value: 232\n",
      "prediction: 171.47 , reel value: 178\n"
     ]
    }
   ],
   "source": [
    "def gradient_descent(X, y, w, b, alpha, num_iters): \n",
    "          \n",
    "          j_history = []\n",
    "          \n",
    "          for i in range(num_iters):\n",
    "                    grad_w, grad_b = compute_gradient(X, y, w, b)\n",
    "\n",
    "                    w = w - alpha * grad_w\n",
    "                    b = b - alpha * grad_b\n",
    "                    \n",
    "                    j_history.append( compute_cost(X, y, w, b))\n",
    "                    if i% num_iters / 10 == 0:\n",
    "                        print(f\"Iteration {i:4d}: Cost {np.sum(j_history[-1])}\")\n",
    "\n",
    "                              \n",
    "          return w, b, j_history\n",
    "      \n",
    "initial_w = np.zeros_like(w_init)\n",
    "initial_b = 0.\n",
    "w , b , j_history = gradient_descent(X_train, y_train, initial_w, initial_b, 5.0e-7, 1000)\n",
    "\n",
    "print(f\"b,w found by gradient descent: {b:0.2f},{w} \")\n",
    "\n",
    "           \n",
    "m,_ = X_train.shape\n",
    "for i in range(m):\n",
    "    print(f\"prediction: {np.dot(X_train[i], w) + b:0.2f} , reel value: {y_train[i]}\")   \n",
    "    \n",
    "          \n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
